{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alheliou/Bias_mitigation/blob/main/UPP26/TD2_mepsdata_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYs3pIgnyGaO"
   },
   "source": [
    "# Préambule : nos biais inconscients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYLnbCt3yGaQ"
   },
   "source": [
    "Nous vous proposons, si vous le souhaitez, de prendre une dizaine de minutes pour tester vos biais inconscients:\n",
    "\n",
    "https://implicit.harvard.edu/implicit/canadafr/takeatest.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "We1Nt1qJyGaQ"
   },
   "source": [
    "# TD 2: Manipulation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_2H62NNyGaR"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "\n",
    " 1. Study the data, the distribution of each feature and its relation to the target.\n",
    "\n",
    " 2. Highlight some bias present in the data\n",
    "\n",
    "\n",
    "## Installation of the environnement\n",
    "\n",
    "We highly recommend you to follow these steps, it will allow every student to work in an environment as similar as possible to the one used during testing.\n",
    "\n",
    "### Colab Settings ---- for Colab Users ONLY\n",
    "  The next two cells of code are too execute only once per colab environment\n",
    "\n",
    "\n",
    "#### 1. Python env creation (Colab only)\n",
    "\n",
    "        ```\n",
    "        ! python -m pip install numpy fairlearn plotly nbformat ipykernel aif360[\"inFairness\"] aif360['AdversarialDebiasing'] causal-learn BlackBoxAuditing cvxpy dice-ml lime shapkit\n",
    "        ```\n",
    "\n",
    "#### 2. Download MEPS dataset (for part2) it can take several minutes (Colab only)\n",
    "\n",
    "        ```\n",
    "        ! Rscript /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/generate_data.R\n",
    "        ! mv h181.csv /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/\n",
    "        ! mv h192.csv /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/\n",
    "        ```\n",
    "\n",
    "  \n",
    "### Local Settings ---- for installation on local computer ONLY\n",
    "\n",
    "You can use the same env as TD1, you will then need to follow steps 2 and 4\n",
    "\n",
    "#### 1. Uv installation (local only, no need to redo if already done)\n",
    "\n",
    "\n",
    "        https://docs.astral.sh/uv/getting-started/installation/\n",
    "\n",
    "\n",
    "        `curl -LsSf https://astral.sh/uv/install.sh | sh`\n",
    "\n",
    "        Python version 3.12 installation (highly recommended)\n",
    "        `uv python install 3.12`\n",
    "\n",
    "#### 2. R installation *NEW* (local only)\n",
    "\n",
    "        In the command `Rscript` says 'command not found'\n",
    "\n",
    "        `sudo apt install r-base-core`\n",
    "\n",
    "#### 3. Python env creation (local only, no need to redo if already done)\n",
    "\n",
    "        ```\n",
    "        mkdir TD_bias_mitigation\n",
    "        cd TD_bias_mitigation\n",
    "        uv python pin 3.12\n",
    "        uv init\n",
    "        uv venv\n",
    "        uv pip install numpy fairlearn plotly nbformat ipykernel aif360[\"inFairness\"] aif360['AdversarialDebiasing'] causal-learn BlackBoxAuditing cvxpy dice-ml lime shapkit\n",
    "        ```\n",
    "\n",
    "#### 4. Download MEPS dataset, it can take several minutes *NEW* (local only)\n",
    "\n",
    "        ```\n",
    "        cd TD_bias_mitigation/.venv/lib/python3.12/site-packages/aif360/data/raw/meps/\n",
    "        Rscript generate_data.R\n",
    "        ```\n",
    "\n",
    "## Dataset: Meps\n",
    "\n",
    "We recommend consulting the following pages for a better understanding of the dataset: [MEPSDataset19](https://aif360.readthedocs.io/en/latest/modules/generated/aif360.datasets.MEPSDataset19.html) and the [AIF360 tutorial](https://github.com/Trusted-AI/AIF360/blob/main/examples/tutorial_medical_expenditure.ipynb)\n",
    "\n",
    "What you need to have read\n",
    "- **The sensitive attribute is 'RACE' :1 is privileged, 0 is unprivileged** ; It is constructed as follows: 'Whites' (privileged class) defined by the features RACEV2X = 1 (White) and HISPANX = 2 (non Hispanic); 'Non-Whites' that included everyone else.\n",
    "(The features 'RACEV2X', 'HISPANX' etc are removed, and replaced by the 'RACE')\n",
    "- **'UTILIZATION' is the outcome (the label to predict for a ML model) 0 is positive 1 is negative**. It is a binary composite feature, created to measure the total number of trips requiring some sort of medical care, it sum up the following features (that are removed from the data):\n",
    "    * OBTOTV15(16), the number of office based visits\n",
    "    * OPTOTV15(16), the number of outpatient visits\n",
    "    * ERTOT15(16), the number of ER visits\n",
    "    * IPNGTD15(16), the number of inpatient nights\n",
    "    * HHTOTD16, the number of home health visits\n",
    "UTILISATION is set to 1 when te sum is above or equal to 10, else it is set to 0\n",
    "- **The dataset is weighted** The dataset come with an 'instance_weights' attribute that corresponds to the feature perwt15f these weights are supposed to generate estimates that are representative of the United State (US) population in 2015.\n",
    "\n",
    "\n",
    "Summary to remember\n",
    "- **The sensitive attribute is 'RACE' :1 is privileged, 0 is unprivileged**\n",
    "- **'UTILIZATION' is the outcome (the label to predict for a ML model) 0 is positive 1 is negative**\n",
    "- **The dataset is weighted**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPjo2_b0yGaS"
   },
   "outputs": [],
   "source": [
    "# To execute only in Colab\n",
    "! python -m pip install numpy fairlearn plotly nbformat ipykernel aif360[inFairness,AdversarialDebiasing] causal-learn BlackBoxAuditing cvxpy dice-ml lime shapkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MZgB70oxyGaS"
   },
   "outputs": [],
   "source": [
    "# Code to compute fairness metrics using aif360\n",
    "\n",
    "from aif360.sklearn.metrics import *\n",
    "from sklearn.metrics import  balanced_accuracy_score\n",
    "\n",
    "\n",
    "# This method takes lists\n",
    "def get_metrics(\n",
    "    y_true, # list or np.array of truth values\n",
    "    y_pred=None,  # list or np.array of predictions\n",
    "    prot_attr=None, # list or np.array of protected/sensitive attribute values\n",
    "    priv_group=1, # value taken by the privileged group\n",
    "    pos_label=1, # value taken by the positive truth/prediction\n",
    "    sample_weight=None # list or np.array of weights value,\n",
    "):\n",
    "    group_metrics = {}\n",
    "    group_metrics[\"base_rate_truth\"] = base_rate(\n",
    "        y_true=y_true, pos_label=pos_label, sample_weight=sample_weight\n",
    "    )\n",
    "    group_metrics[\"statistical_parity_difference\"] = statistical_parity_difference(\n",
    "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
    "    )\n",
    "    group_metrics[\"disparate_impact_ratio\"] = disparate_impact_ratio(\n",
    "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
    "    )\n",
    "    if not y_pred is None:\n",
    "        group_metrics[\"base_rate_preds\"] = base_rate(\n",
    "        y_true=y_pred, pos_label=pos_label, sample_weight=sample_weight\n",
    "        )\n",
    "        group_metrics[\"equal_opportunity_difference\"] = equal_opportunity_difference(\n",
    "            y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
    "        )\n",
    "        group_metrics[\"average_odds_difference\"] = average_odds_difference(\n",
    "            y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
    "        )\n",
    "        if len(set(y_pred))>1:\n",
    "            group_metrics[\"conditional_demographic_disparity\"] = conditional_demographic_disparity(\n",
    "                y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
    "            )\n",
    "        else:\n",
    "            group_metrics[\"conditional_demographic_disparity\"] =None\n",
    "        group_metrics[\"smoothed_edf\"] = smoothed_edf(\n",
    "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
    "        )\n",
    "        group_metrics[\"df_bias_amplification\"] = df_bias_amplification(\n",
    "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
    "        )\n",
    "        group_metrics[\"balanced_accuracy_score\"] = balanced_accuracy_score(\n",
    "        y_true=y_true, y_pred=y_pred, sample_weight=sample_weight\n",
    "        )\n",
    "    return group_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_KZGlcqyGaT"
   },
   "source": [
    "In this TD we will use data from the [Medical Expenditure Panel Survey](https://meps.ahrq.gov/mepsweb/). The TD is inspired from [AIF360 tutorial](https://github.com/Trusted-AI/AIF360/blob/main/examples/tutorial_medical_expenditure.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3jVgGzLGyGaT"
   },
   "source": [
    "## The Meps dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GxLtOGFKyGaT"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', append=True, category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PQ2s5iHyGaT"
   },
   "outputs": [],
   "source": [
    "# Datasets\n",
    "from aif360.datasets import MEPSDataset19\n",
    "from aif360.datasets import MEPSDataset20\n",
    "from aif360.datasets import MEPSDataset21\n",
    "\n",
    "MEPSDataset19_data = MEPSDataset19()\n",
    "# (dataset_orig_panel19_train,\n",
    "#  dataset_orig_panel19_val,\n",
    "#  dataset_orig_panel19_test) = MEPSDataset19_data.split([0.5, 0.8], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-ZuMGWkyGaU"
   },
   "outputs": [],
   "source": [
    "(dataset_orig_panel19_train,\n",
    " dataset_orig_panel19_val,\n",
    " dataset_orig_panel19_test) = MEPSDataset19().split([0.5, 0.8], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TeAU4a4FyGaU"
   },
   "outputs": [],
   "source": [
    "len(dataset_orig_panel19_train.instance_weights), len(dataset_orig_panel19_val.instance_weights), len(dataset_orig_panel19_test.instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q9DzVakiyGaU"
   },
   "outputs": [],
   "source": [
    "instance_weights = MEPSDataset19_data.instance_weights\n",
    "instance_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F2xo5mq5yGaU"
   },
   "outputs": [],
   "source": [
    "f\"Taille du dataset {len(instance_weights)}, poids total du dataset {instance_weights.sum()}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0b1z_UsyGaU"
   },
   "source": [
    "### Premier appercu du dataset\n",
    "\n",
    "La librairie AIF360 fournie une surcouche au dataset, cela le rend un peu moins intuitif d'utilisation (par exemple pour étudier/visualiser les attributs un à un), mais elle permet de calculer les métrique des fairness en une ligne de commande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNOdePnZyGaU"
   },
   "outputs": [],
   "source": [
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "metric_orig_panel19_train = BinaryLabelDatasetMetric(\n",
    "        MEPSDataset19_data,\n",
    "        unprivileged_groups=[{'RACE': 0}],\n",
    "        privileged_groups=[{'RACE': 1}])\n",
    "\n",
    "print(metric_orig_panel19_train.disparate_impact())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEBHgvlTyGaV"
   },
   "source": [
    "Cependant le but de ce TD étant encore de manipuler les données et de les analyser nous allons revenir aux données sous forme d'un dataframe.\n",
    "\n",
    "Note pour calculer les métriques de fairness sans avoir à les réimplémenter dans le cas pondéré (instances weights) vous pouvez utiliser les méthodes implémenter dans AIF360 là [Implémentation Métriques de Fairness](https://aif360.readthedocs.io/en/latest/modules/sklearn.html#module-aif360.sklearn.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9a-m4nX5yGaV"
   },
   "source": [
    "### Conversion en un dataframe\n",
    "\n",
    "Nous avons vu que la somme des poids est conséquente, pres de 115millions nous ne pouvons donc pas raisonneblement dupliqué chaque ligne autant de fois que son poids.\n",
    "\n",
    "Nous allons stocker la pondération et la prendre en compte ensuite dans notre analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DwMdbzT5yGaV"
   },
   "outputs": [],
   "source": [
    "def get_df(MepsDataset):\n",
    "    data = MepsDataset.convert_to_dataframe()\n",
    "    # data_train est un tuple, avec le data_frame et un dictionnaire avec toutes les infos (poids, attributs sensibles etc)\n",
    "    df = data[0]\n",
    "    df['WEIGHT'] = data[1]['instance_weights']\n",
    "    return df\n",
    "\n",
    "df = get_df(MEPSDataset19_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DRzPJgfzyGaV"
   },
   "outputs": [],
   "source": [
    "from aif360.sklearn.metrics import disparate_impact_ratio, base_rate\n",
    "dir = disparate_impact_ratio(\n",
    "    y_true=df.UTILIZATION,\n",
    "    prot_attr=df.RACE,\n",
    "    pos_label=0,\n",
    "    sample_weight=df.WEIGHT)\n",
    "br =base_rate(\n",
    "    y_true=df.UTILIZATION,\n",
    "    pos_label=0,\n",
    "    sample_weight=df.WEIGHT)\n",
    "dir,br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQduzXQ0yGaV"
   },
   "outputs": [],
   "source": [
    "dir = disparate_impact_ratio(\n",
    "    y_true=df.UTILIZATION,\n",
    "    prot_attr=df.RACE,\n",
    "    pos_label=0)\n",
    "br =base_rate(\n",
    "    y_true=df.UTILIZATION,\n",
    "    pos_label=0)\n",
    "dir,br"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5DCh_-VyGaV"
   },
   "source": [
    "## Question 1 - Apprendre un modèle pour prédire le fait d'être réadmis\n",
    "### 1.1 - Faire le pre-processing des données\n",
    "\n",
    "Ici ce pre-processing a déjà été fait par AIF, nous avons simplement converti le dataset en dataframe pour pouvoir le manipuler librement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFsE8riZyGaW"
   },
   "source": [
    "### Question 1.2 - Creer les échantillons d'apprentissage, de validation et de test\n",
    "\n",
    "Pour créer le df_X il faut enlever l'outcome (\"UTILIZATION\") et la pondération (\"WEIGHT\")\n",
    "\n",
    "La colonne \"UTILIZATION\" sera le label (noté y)\n",
    "\n",
    "La colonne \"WEIGHT\" sera la pondération (notée w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZss_K5fyGaW"
   },
   "outputs": [],
   "source": [
    "# Question 1.2: Créer les échantillons d'apprentissage, de validation et de test\n",
    "\n",
    "from sklearn.model_selection import train_test_splitprint(f\"Test set: {len(X_test)} samples\")\n",
    "\n",
    "print(f\"Validation set: {len(X_val)} samples\")\n",
    "\n",
    "# Créer df_X en enlevant UTILIZATION et WEIGHTprint(f\"Train set: {len(X_train)} samples\")\n",
    "\n",
    "df_X = df.drop(columns=['UTILIZATION', 'WEIGHT'])\n",
    "\n",
    "y = df['UTILIZATION'])\n",
    "\n",
    "w = df['WEIGHT']    X_temp, y_temp, w_temp, test_size=0.375, random_state=42, stratify=y_temp  # 0.375 * 0.8 = 0.3\n",
    "\n",
    "X_train, X_val, y_train, y_val, w_train, w_val = train_test_split(\n",
    "\n",
    "# Split en train, validation et test (50%, 30%, 20%)\n",
    "\n",
    "X_temp, X_test, y_temp, y_test, w_temp, w_test = train_test_split()\n",
    "    df_X, y, w, test_size=0.2, random_state=42, stratify=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xG1ni3EAyGaW"
   },
   "outputs": [],
   "source": [
    "df_X.shape, X_train.shape, y_train.shape, w_train.shape, X_val.shape, y_val.shape, w_val.shape,  X_test.shape, y_test.shape, w_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmV5PJb_yGaW"
   },
   "source": [
    "### Question 1.3 - Apprendre une regression logistique dont le but est de prédire UTILIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "thzyZI31yGaW"
   },
   "outputs": [],
   "source": [
    "# Question 1.3: Apprendre une régression logistique\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionprint(f\"Score sur test: {log_reg.score(X_test, y_test, sample_weight=w_test):.4f}\")\n",
    "\n",
    "print(f\"Score sur validation: {log_reg.score(X_val, y_val, sample_weight=w_val):.4f}\")\n",
    "\n",
    "# Créer et entraîner le modèle avec pondérationprint(f\"Score sur train: {log_reg.score(X_train, y_train, sample_weight=w_train):.4f}\")\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "log_reg.fit(X_train, y_train, sample_weight=w_train)y_pred_test = log_reg.predict(X_test)\n",
    "\n",
    "y_pred_val = log_reg.predict(X_val)\n",
    "\n",
    "# Prédictionsy_pred_train = log_reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBhOmDg5yGaW"
   },
   "source": [
    "### Quesiton 1.4 Performance du modèle (afficher la matrice de confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zmk-A5beyGaW"
   },
   "outputs": [],
   "source": [
    "# Question 1.4: Matrice de confusion\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplayprint(f\"Vrais Positifs (TP): {cm[1, 1]:.0f}\")\n",
    "\n",
    "import matplotlib.pyplot as pltprint(f\"Faux Négatifs (FN): {cm[1, 0]:.0f}\")\n",
    "\n",
    "print(f\"Faux Positifs (FP): {cm[0, 1]:.0f}\")\n",
    "\n",
    "# Matrice de confusion sur le test setprint(f\"\\nVrais Négatifs (TN): {cm[0, 0]:.0f}\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_test, sample_weight=w_test)print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Low Utilization', 'High Utilization'])print(\"\\nMatrice de confusion (pondérée):\")\n",
    "\n",
    "disp.plot(cmap='Blues')\n",
    "\n",
    "plt.title('Matrice de Confusion - Test Set (Weighted)')plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bh-3PyTByGaW"
   },
   "source": [
    "### Question 1.5 - Calculer les métriques \"group fairness\" du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SUvR6Eb0yGaW"
   },
   "outputs": [],
   "source": [
    "# Question 1.5: Calculer les métriques \"group fairness\"\n",
    "\n",
    "# Extraire l'attribut sensible RACE du test setprint(\"- Equal Opportunity Difference proche de 0 = équitable\")\n",
    "\n",
    "race_test = X_test['RACE'].valuesprint(\"- Statistical Parity Difference proche de 0 = équitable\")\n",
    "\n",
    "print(\"- Disparate Impact Ratio proche de 1 = équitable\")\n",
    "\n",
    "# Calculer les métriques de fairness avec pondérationprint(\"\\nInterprétation:\")\n",
    "\n",
    "print(\"=== Métriques de Group Fairness (RACE) ===\")\n",
    "\n",
    "print(\"Groupe privilégié: White (RACE=1) | Groupe défavorisé: Non-White (RACE=0)\\n\")        print(f\"{metric_name}: None\")\n",
    "\n",
    "    else:\n",
    "\n",
    "metrics = get_metrics(        print(f\"{metric_name}: {metric_value:.4f}\")\n",
    "\n",
    "    y_true=y_test.values,    if metric_value is not None:\n",
    "\n",
    "    y_pred=y_pred_test,for metric_name, metric_value in metrics.items():\n",
    "\n",
    "    prot_attr=race_test,\n",
    "\n",
    "    priv_group=1,)\n",
    "\n",
    "    pos_label=0,  # 0 est le label positif selon la description    sample_weight=w_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEVsJaRYyGaX"
   },
   "source": [
    "## Question 2 - Etude de l'impact de la couleur de peau sur le faire d'être réadmis, les prédictions du modèle et ses liens avec les autres variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSNi89MVyGaX"
   },
   "source": [
    "### Question 2.1 - Faire l'étude descriptive univarié de la couleur de peau ('RACE') (effectif, fréquence, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IuS8zFVyGaX"
   },
   "outputs": [],
   "source": [
    "# Question 2.1: Étude descriptive univariée de RACE\n",
    "\n",
    "print(\"=== Analyse Univariée de RACE ===\")print(\"Mode (pondéré):\", race_weighted.idxmax())\n",
    "\n",
    "print(\"\\nEffectifs:\")print(\"\\nMode (non pondéré):\", df['RACE'].mode().values[0])\n",
    "\n",
    "print(df['RACE'].value_counts().sort_index())\n",
    "\n",
    "print(race_weighted / race_weighted.sum())\n",
    "\n",
    "print(\"\\nEffectifs pondérés:\")print(\"\\nFréquences pondérées:\")\n",
    "\n",
    "race_weighted = df.groupby('RACE')['WEIGHT'].sum()\n",
    "\n",
    "print(race_weighted)print(df['RACE'].value_counts(normalize=True).sort_index())\n",
    "\n",
    "print(\"\\nFréquences:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATy9yZPqyGaX"
   },
   "source": [
    "### Question 2.2 - Faire des graphiques décrivant la couleur de peau  (diagramme en secteur, diagramme en barres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yHzZ00EFyGaX"
   },
   "outputs": [],
   "source": [
    "# Question 2.2: Graphiques décrivant RACE\n",
    "\n",
    "import plotly.graph_objects as gofig.show()\n",
    "\n",
    "             title='Distribution de RACE - Diagramme en barres (non pondéré)')\n",
    "\n",
    "# Diagramme en secteur (pondéré)             labels={'x': 'RACE', 'y': 'Nombre d\\'observations'},\n",
    "\n",
    "race_counts = df.groupby('RACE')['WEIGHT'].sum()fig = px.bar(x=labels, y=race_counts_unweighted.values,\n",
    "\n",
    "labels = ['Non-White (0)', 'White (1)']race_counts_unweighted = df['RACE'].value_counts().sort_index()\n",
    "\n",
    "fig = px.pie(values=race_counts.values, names=labels, # Diagramme en barres (non pondéré)\n",
    "\n",
    "             title='Distribution de RACE (pondérée)')\n",
    "\n",
    "fig.show()fig.show()\n",
    "\n",
    "             title='Distribution de RACE - Diagramme en barres (pondéré)')\n",
    "\n",
    "# Diagramme en barres (pondéré)             labels={'x': 'RACE', 'y': 'Poids total'},\n",
    "fig = px.bar(x=labels, y=race_counts.values,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wf5mMt7PyGaX"
   },
   "source": [
    "### Question 2.3 - Faire l'analyse bivariée entre la couleur de peau et les autres variables explicatives quantitatives (boite à moustaches des variables par genre, densité/histogramme par genre, rapport de corrélation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qd2pJnOtyGaX"
   },
   "outputs": [],
   "source": [
    "# Question 2.3: Analyse bivariée RACE vs variables quantitatives\n",
    "\n",
    "# Variables quantitatives dans le dataset    print(f\"{var}: {eta_squared:.4f}\")\n",
    "\n",
    "quant_vars = df.select_dtypes(include=[np.number]).columns.tolist()    eta_squared = ss_between / ss_total if ss_total > 0 else 0\n",
    "\n",
    "quant_vars = [v for v in quant_vars if v not in ['RACE', 'UTILIZATION', 'WEIGHT']]    ss_total = sum([(x - grand_mean)**2 for x in df[var]])\n",
    "\n",
    "    ss_between = sum([len(g) * (np.mean(g) - grand_mean)**2 for g in groups])\n",
    "\n",
    "print(f\"Variables quantitatives analysées: {quant_vars[:5]}...\")  # Afficher quelques-unes    grand_mean = df[var].mean()\n",
    "\n",
    "    groups = df.groupby('RACE')[var].apply(list)\n",
    "\n",
    "# Boxplots pour quelques variables clés    # Calculer eta²\n",
    "\n",
    "for var in quant_vars[:3]:  # Afficher les 3 premières pour exemplefor var in quant_vars[:5]:\n",
    "\n",
    "    fig = px.box(df, x='RACE', y=var, print(\"\\nRapport de corrélation (eta²) entre RACE et variables quantitatives:\")\n",
    "\n",
    "                 title=f'Boxplot de {var} par RACE',# Rapport de corrélation (eta²) pour mesurer la dépendance\n",
    "\n",
    "                 labels={'RACE': 'RACE (0=Non-White, 1=White)'})\n",
    "\n",
    "    fig.show()    fig.show()\n",
    "\n",
    "                       barmode='overlay', opacity=0.7)\n",
    "\n",
    "# Histogrammes par RACE pour une variable                       title=f'Distribution de {var} par RACE',\n",
    "\n",
    "if len(quant_vars) > 0:    fig = px.histogram(df, x=var, color='RACE',\n",
    "    var = quant_vars[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7n0Hvju5yGaX"
   },
   "source": [
    "### Question 2.4 - Faire l'analyse bivariée entre la couelur de peau et d'autres variables explicatives qualitative (table de contingence, diagramme en barre selon les profils lignes et selon les profils colonnes, diagramme en mosaique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0ditZXYyGad"
   },
   "outputs": [],
   "source": [
    "# Question 2.4: Analyse bivariée RACE vs variables qualitatives\n",
    "\n",
    "# Variables qualitatives (on peut considérer certaines variables binaires comme qualitatives)print(f\"\\nTest du Chi²: chi2={chi2:.2f}, p-value={p_value:.4f}\")\n",
    "\n",
    "# Pour cet exemple, créons une variable catégorielle à partir de l'âge si disponiblechi2, p_value, dof, expected = chi2_contingency(contingency_weighted)\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Table de contingence avec UTILIZATION# Test du Chi²\n",
    "\n",
    "print(\"=== Table de contingence: RACE x UTILIZATION ===\")\n",
    "\n",
    "contingency = pd.crosstab(df['RACE'], df['UTILIZATION'])fig.show()\n",
    "\n",
    "print(contingency)             barmode='group')\n",
    "\n",
    "             labels={'value': 'Pourcentage', 'RACE': 'RACE (0=Non-White, 1=White)'},\n",
    "\n",
    "print(\"\\nTable de contingence pondérée:\")             title='Profils lignes: Distribution de UTILIZATION par RACE',\n",
    "\n",
    "contingency_weighted = pd.crosstab(df['RACE'], df['UTILIZATION'],              x='RACE', y='value', color='UTILIZATION',\n",
    "\n",
    "                                    values=df['WEIGHT'], aggfunc='sum')fig = px.bar(profiles_row.reset_index().melt(id_vars='RACE'),\n",
    "\n",
    "print(contingency_weighted)# Diagramme en barres groupées\n",
    "\n",
    "\n",
    "\n",
    "# Profils lignes (distribution de UTILIZATION par RACE)print(profiles_col)\n",
    "\n",
    "print(\"\\nProfils lignes (% par ligne):\")profiles_col = contingency_weighted.div(contingency_weighted.sum(axis=0), axis=1) * 100\n",
    "\n",
    "profiles_row = contingency_weighted.div(contingency_weighted.sum(axis=1), axis=0) * 100print(\"\\nProfils colonnes (% par colonne):\")\n",
    "\n",
    "print(profiles_row)# Profils colonnes (distribution de RACE par UTILIZATION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSSmGzWuyGad"
   },
   "source": [
    "### Question 2.5 - Faire l'analyse bivariée entre la couleur de peau et la colonne 'UTILIZATION'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oN3y3l1RyGad"
   },
   "outputs": [],
   "source": [
    "# Question 2.5: Analyse bivariée RACE vs UTILIZATION\n",
    "\n",
    "print(\"=== Analyse détaillée: RACE vs UTILIZATION ===\")print(f\"\\nDisparate Impact Ratio (UTILIZATION): {dir_util:.4f}\")\n",
    "\n",
    ")\n",
    "\n",
    "# Taux d'utilisation par race (pondéré)    sample_weight=df['WEIGHT']\n",
    "\n",
    "util_by_race = df.groupby('RACE').apply(    pos_label=0,\n",
    "\n",
    "    lambda x: (x['UTILIZATION'] == 0).sum() * x['WEIGHT'].iloc[0] if len(x) > 0 else 0    priv_group=1,\n",
    "\n",
    ")    prot_attr=df['RACE'],\n",
    "\n",
    "total_by_race = df.groupby('RACE')['WEIGHT'].sum()    y_true=df['UTILIZATION'],\n",
    "\n",
    "rate_by_race = util_by_race / total_by_racedir_util = disparate_impact_ratio(\n",
    "\n",
    "from aif360.sklearn.metrics import disparate_impact_ratio\n",
    "\n",
    "print(\"\\nTaux d'utilisation élevée (UTILIZATION=0) par RACE:\")# Calculer le disparate impact\n",
    "\n",
    "for race in [0, 1]:\n",
    "\n",
    "    print(f\"RACE {race}: {rate_by_race[race]:.4f}\")fig.show()\n",
    "\n",
    "                   y='WEIGHT')\n",
    "\n",
    "# Graphique                   histfunc='sum',\n",
    "\n",
    "fig = px.histogram(df, x='RACE', color='UTILIZATION',                   barmode='group',\n",
    "\n",
    "                   title='Distribution de UTILIZATION par RACE',                   labels={'RACE': 'RACE (0=Non-White, 1=White)'},\n",
    "\n",
    "                   labels={'RACE': 'RACE (0=Non-White, 1=White)'},                   title='Distribution de UTILIZATION par RACE (avec pondération)',\n",
    "\n",
    "                   barmode='group')fig = px.histogram(df_plot, x='RACE', color='UTILIZATION',\n",
    "\n",
    "fig.show()df_plot = df.copy()\n",
    "\n",
    "# Avec pondération"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_AIhVS-yGae"
   },
   "source": [
    "### Question 2.6 - Faire l'analyse bivariée entre la couleur de peau et les prédictions du modèle prédisant la colonne 'UTILIZATION'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQ03WvR9yGae"
   },
   "outputs": [],
   "source": [
    "# Question 2.6: Analyse bivariée RACE vs prédictions du modèle\n",
    "\n",
    "print(\"=== Analyse: RACE vs Prédictions du Modèle ===\")print(f\"\\nDisparate Impact Ratio (Prédictions): {dir_pred:.4f}\")\n",
    "\n",
    ")\n",
    "\n",
    "# Prédictions sur l'ensemble du dataset    sample_weight=df_with_pred['WEIGHT']\n",
    "\n",
    "y_pred_all = log_reg.predict(df_X)    pos_label=0,\n",
    "\n",
    "    priv_group=1,\n",
    "\n",
    "# Taux de prédictions positives par race    prot_attr=df_with_pred['RACE'],\n",
    "\n",
    "df_with_pred = df.copy()    y_true=df_with_pred['PREDICTION'],\n",
    "\n",
    "df_with_pred['PREDICTION'] = y_pred_alldir_pred = disparate_impact_ratio(\n",
    "\n",
    "# Disparate impact sur les prédictions\n",
    "\n",
    "# Calculer les taux par race (pondéré)\n",
    "\n",
    "for race in [0, 1]:print(contingency_pred)\n",
    "\n",
    "    mask = df_with_pred['RACE'] == raceprint(\"\\nTable de contingence pondérée (RACE x PREDICTION):\")\n",
    "\n",
    "    rate_pos = ((df_with_pred[mask]['PREDICTION'] == 0) * df_with_pred[mask]['WEIGHT']).sum() / df_with_pred[mask]['WEIGHT'].sum()                                values=df_with_pred['WEIGHT'], aggfunc='sum')\n",
    "\n",
    "    print(f\"RACE {race}: Taux de prédiction positive (PREDICTION=0): {rate_pos:.4f}\")contingency_pred = pd.crosstab(df_with_pred['RACE'], df_with_pred['PREDICTION'],\n",
    "\n",
    "# Table de contingence\n",
    "\n",
    "# Graphique\n",
    "\n",
    "fig = px.histogram(df_with_pred, x='RACE', color='PREDICTION',fig.show()\n",
    "\n",
    "                   title='Distribution des Prédictions par RACE',                   barmode='group')\n",
    "                   labels={'RACE': 'RACE (0=Non-White, 1=White)'},"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rx5Bs8qhyGae"
   },
   "source": [
    "### Question 2.7 - Faire l'analyse bivariée entre la couleur de peau et les erreurs du modèle précédent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQRlN9K7yGae"
   },
   "outputs": [],
   "source": [
    "# Question 2.7: Analyse bivariée RACE vs erreurs du modèle\n",
    "\n",
    "print(\"=== Analyse: RACE vs Erreurs du Modèle ===\")fig.show()\n",
    "\n",
    "                   barmode='stack')\n",
    "\n",
    "# Créer une colonne d'erreurs                   labels={'RACE': 'RACE (0=Non-White, 1=White)'},\n",
    "\n",
    "df_with_pred['ERROR'] = (df_with_pred['UTILIZATION'] != df_with_pred['PREDICTION']).astype(int)                   title='Types d\\'Erreurs par RACE',\n",
    "\n",
    "fig = px.histogram(df_with_pred, x='RACE', color='ERROR_TYPE',\n",
    "\n",
    "# Taux d'erreur par race\n",
    "\n",
    "for race in [0, 1]:df_with_pred.loc[(df_with_pred['UTILIZATION'] == 0) & (df_with_pred['PREDICTION'] == 1), 'ERROR_TYPE'] = 'Faux Négatif'\n",
    "\n",
    "    mask = df_with_pred['RACE'] == racedf_with_pred.loc[(df_with_pred['UTILIZATION'] == 1) & (df_with_pred['PREDICTION'] == 0), 'ERROR_TYPE'] = 'Faux Positif'\n",
    "\n",
    "    error_rate = (df_with_pred[mask]['ERROR'] * df_with_pred[mask]['WEIGHT']).sum() / df_with_pred[mask]['WEIGHT'].sum()df_with_pred['ERROR_TYPE'] = 'Correct'\n",
    "\n",
    "    print(f\"RACE {race}: Taux d'erreur: {error_rate:.4f}\")# Analyse des types d'erreurs\n",
    "\n",
    "\n",
    "\n",
    "# Types d'erreurs par racefig.show()\n",
    "\n",
    "for race in [0, 1]:                   barmode='group')\n",
    "\n",
    "    mask = df_with_pred['RACE'] == race                           'ERROR': 'Erreur (0=Correct, 1=Erreur)'},\n",
    "\n",
    "    df_race = df_with_pred[mask]                   labels={'RACE': 'RACE (0=Non-White, 1=White)', \n",
    "\n",
    "                       title='Distribution des Erreurs par RACE',\n",
    "\n",
    "    # Faux positifsfig = px.histogram(df_with_pred, x='RACE', color='ERROR',\n",
    "\n",
    "    fp = ((df_race['UTILIZATION'] == 1) & (df_race['PREDICTION'] == 0)).sum()# Visualisation des erreurs par race\n",
    "\n",
    "    # Faux négatifs\n",
    "\n",
    "    fn = ((df_race['UTILIZATION'] == 0) & (df_race['PREDICTION'] == 1)).sum()    print(f\"  Faux Négatifs: {fn}\")\n",
    "\n",
    "        print(f\"  Faux Positifs: {fp}\")\n",
    "    print(f\"\\nRACE {race}:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dqdpoztyGae"
   },
   "source": [
    "### Question 2.8 - Proposer un modèle à base d'une foret aléatoire prédisant la couleur de peau en fonction des autres variables explicatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "peRtGr7GyGae"
   },
   "outputs": [],
   "source": [
    "# Question 2.8: Modèle de forêt aléatoire prédisant RACE\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifierprint(\"à partir des autres variables, suggérant un risque de proxy discrimination.\")\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_scoreprint(\"\\nInterprétation: Un score élevé indique que RACE est fortement prédictible\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"=== Modèle prédisant RACE à partir des autres variables ===\")fig.show()\n",
    "\n",
    "             title='Importance des Features pour Prédire RACE')\n",
    "\n",
    "# Préparer les données (enlever RACE, UTILIZATION, WEIGHT)             orientation='h',\n",
    "\n",
    "X_race = df.drop(columns=['RACE', 'UTILIZATION', 'WEIGHT'])fig = px.bar(feature_importance.head(10), x='importance', y='feature',\n",
    "\n",
    "y_race = df['RACE']# Visualisation\n",
    "\n",
    "w_race = df['WEIGHT']\n",
    "\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Split train/testprint(\"\\nTop 10 features les plus importantes:\")\n",
    "\n",
    "X_train_race, X_test_race, y_train_race, y_test_race, w_train_race, w_test_race = train_test_split(\n",
    "\n",
    "    X_race, y_race, w_race, test_size=0.2, random_state=42, stratify=y_race}).sort_values('importance', ascending=False)\n",
    "\n",
    ")    'importance': rf_race.feature_importances_\n",
    "\n",
    "    'feature': X_race.columns,\n",
    "\n",
    "# Entraîner une forêt aléatoirefeature_importance = pd.DataFrame({\n",
    "\n",
    "rf_race = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)# Importance des features\n",
    "\n",
    "rf_race.fit(X_train_race, y_train_race, sample_weight=w_train_race)\n",
    "\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test_race, y_proba_race, sample_weight=w_test_race):.4f}\")\n",
    "\n",
    "# Prédictionsprint(f\"\\nScore sur le test set: {rf_race.score(X_test_race, y_test_race, sample_weight=w_test_race):.4f}\")\n",
    "\n",
    "y_pred_race = rf_race.predict(X_test_race)# Performance\n",
    "\n",
    "y_proba_race = rf_race.predict_proba(X_test_race)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhvJWueiyGae"
   },
   "source": [
    "### Question 2.9 - Apprendre un modèle privé de la couleur de peau pour prédire UTILIZATION et étudier le lien entre ses prédictions et la couleur de peau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AsPjEMxMyGae"
   },
   "outputs": [],
   "source": [
    "# Question 2.9: Modèle sans RACE pour prédire UTILIZATION\n",
    "\n",
    "print(\"=== Modèle sans RACE pour prédire UTILIZATION ===\")print(f\"Score sans RACE: {log_reg_no_race.score(X_test_nr, y_test_nr, sample_weight=w_test_nr):.4f}\")\n",
    "\n",
    "print(f\"Score avec RACE: {log_reg.score(X_test, y_test, sample_weight=w_test):.4f}\")\n",
    "\n",
    "# Créer les données sans RACEprint(\"\\n=== Comparaison des modèles ===\")\n",
    "\n",
    "X_no_race = df.drop(columns=['RACE', 'UTILIZATION', 'WEIGHT'])# Comparaison avec le modèle incluant RACE\n",
    "\n",
    "y_util = df['UTILIZATION']\n",
    "\n",
    "w_util = df['WEIGHT']print(\"cela suggère une discrimination par proxy via d'autres variables corrélées à RACE.\")\n",
    "\n",
    "print(\"\\nInterprétation: Si le disparate impact persiste même sans RACE,\")\n",
    "\n",
    "# Split train/test\n",
    "\n",
    "X_train_nr, X_test_nr, y_train_nr, y_test_nr, w_train_nr, w_test_nr = train_test_split(    print(f\"RACE {race}: Taux de prédiction positive: {rate:.4f}\")\n",
    "\n",
    "    X_no_race, y_util, w_util, test_size=0.2, random_state=42, stratify=y_util    rate = ((y_pred_nr[mask] == 0) * w_test_nr.values[mask]).sum() / w_test_nr.values[mask].sum()\n",
    "\n",
    ")    mask = race_test_nr == race\n",
    "\n",
    "for race in [0, 1]:\n",
    "\n",
    "# Entraîner une régression logistique sans RACE# Taux de prédictions positives par race\n",
    "\n",
    "log_reg_no_race = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "log_reg_no_race.fit(X_train_nr, y_train_nr, sample_weight=w_train_nr)print(f\"Disparate Impact Ratio des prédictions: {dir_no_race:.4f}\")\n",
    "\n",
    ")\n",
    "\n",
    "# Prédictions    sample_weight=w_test_nr.values\n",
    "\n",
    "y_pred_nr = log_reg_no_race.predict(X_test_nr)    pos_label=0,\n",
    "\n",
    "    priv_group=1,\n",
    "\n",
    "print(f\"\\nScore sur le test set: {log_reg_no_race.score(X_test_nr, y_test_nr, sample_weight=w_test_nr):.4f}\")    prot_attr=race_test_nr,\n",
    "\n",
    "    y_true=y_pred_nr,\n",
    "\n",
    "# Analyser le lien entre les prédictions et RACEdir_no_race = disparate_impact_ratio(\n",
    "\n",
    "race_test_nr = df.loc[y_test_nr.index, 'RACE'].values# Disparate impact\n",
    "\n",
    "\n",
    "print(\"\\n=== Lien entre les prédictions (sans RACE) et RACE ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMblug30yGaf"
   },
   "source": [
    "## Question 3 - Faire de meme pour une autre variable sensible (Age, genre, marry etc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fq7vhHbYyGaf"
   },
   "outputs": [],
   "source": [
    "# Question 3: Analyse pour une autre variable sensible\n",
    "\n",
    "print(\"=== Analyse pour une autre variable sensible: Exemple avec une variable d'âge ===\")    print(\"Vous pouvez créer une variable d'âge binaire (jeune/âgé) ou autre variable catégorielle.\")\n",
    "\n",
    "    print(\"\\nPas assez de variables binaires pour l'analyse.\")\n",
    "\n",
    "# Explorer les colonnes disponibleselse:\n",
    "\n",
    "print(\"\\nColonnes disponibles dans le dataset:\")                print(f\"{metric_name}: {metric_value:.4f}\")\n",
    "\n",
    "print(df.columns.tolist())            if metric_value is not None:\n",
    "\n",
    "        for metric_name, metric_value in metrics_alt.items():\n",
    "\n",
    "# Créer une variable binaire d'âge si elle n'existe pas déjà        print(f\"\\n=== Métriques de Fairness pour {sensitive_var} ===\")\n",
    "\n",
    "# (adapter selon les colonnes réellement présentes dans le dataset)        \n",
    "\n",
    "        )\n",
    "\n",
    "# Exemple d'analyse pour toute variable binaire disponible            sample_weight=w_test.values\n",
    "\n",
    "binary_cols = [col for col in df.columns if df[col].nunique() == 2 and col not in ['UTILIZATION', 'WEIGHT']]            pos_label=0,\n",
    "\n",
    "            priv_group=priv_value,\n",
    "\n",
    "if len(binary_cols) > 1:            prot_attr=sensitive_test,\n",
    "\n",
    "    sensitive_var = binary_cols[0]  # Prendre la première variable binaire autre que RACE            y_pred=y_pred_test,\n",
    "\n",
    "    print(f\"\\nAnalyse de la variable sensible: {sensitive_var}\")            y_true=y_test.values,\n",
    "\n",
    "            metrics_alt = get_metrics(\n",
    "\n",
    "    # Distribution        \n",
    "\n",
    "    print(f\"\\nDistribution de {sensitive_var}:\")        priv_value = df[sensitive_var].mode().values[0]\n",
    "\n",
    "    print(df[sensitive_var].value_counts())        sensitive_test = X_test[sensitive_var].values\n",
    "\n",
    "        if sensitive_var in X_test.columns:\n",
    "    # Métriques de fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXhVhJF7yGaf"
   },
   "source": [
    "## Question 4 - Causalité: appliquer le module causal-learn sur le jeu de données en testant plusieurs des méthodes implémentées et en comparant les résultats entre les méthodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ohKlj1ZIyGaf"
   },
   "outputs": [],
   "source": [
    "# Question 4: Causalité avec causal-learn\n",
    "\n",
    "print(\"=== Analyse de Causalité avec causal-learn ===\")print(\"Des chemins indirects suggèrent une médiation par d'autres variables.\")\n",
    "\n",
    "print(\"Une arête de RACE vers UTILIZATION suggère une influence causale directe.\")\n",
    "\n",
    "from causallearn.search.ConstraintBased.PC import pcprint(\"Comparez les résultats des différentes méthodes pour identifier les relations robustes.\")\n",
    "\n",
    "from causallearn.utils.GraphUtils import GraphUtilsprint(\"Les graphes causaux montrent les relations de causalité potentielles entre variables.\")\n",
    "\n",
    "import matplotlib.image as mpimgprint(\"\\n=== Interprétation ===\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "    print(f\"Erreur avec GES: {e}\")\n",
    "\n",
    "# Préparer un sous-ensemble de données pour l'analyse causaleexcept Exception as e:\n",
    "\n",
    "# (prendre un échantillon car les algorithmes peuvent être lents)    plt.show()\n",
    "\n",
    "np.random.seed(42)    plt.title('Graphe Causal - Algorithme GES')\n",
    "\n",
    "sample_size = min(1000, len(df))    plt.axis('off')\n",
    "\n",
    "sample_indices = np.random.choice(len(df), sample_size, replace=False)    plt.imshow(img)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Sélectionner quelques variables clés    img = mpimg.imread('causal_graph_ges.png')\n",
    "\n",
    "key_vars = ['RACE', 'UTILIZATION'] + [col for col in df.columns if col not in ['RACE', 'UTILIZATION', 'WEIGHT']][:5]    \n",
    "\n",
    "df_causal = df.iloc[sample_indices][key_vars].copy()    pyd.write_png('causal_graph_ges.png')\n",
    "\n",
    "    pyd = GraphUtils.to_pydot(record['G'], labels=key_vars)\n",
    "\n",
    "print(f\"\\nVariables utilisées pour l'analyse causale: {key_vars}\")    \n",
    "\n",
    "print(f\"Taille de l'échantillon: {len(df_causal)}\")    print(\"Graphe causal obtenu avec GES algorithm\")\n",
    "\n",
    "    record = ges(data_array, score_func='local_score_BIC')\n",
    "\n",
    "# Convertir en array numpy    \n",
    "\n",
    "data_array = df_causal.values    from causallearn.search.ScoreBased.GES import ges\n",
    "\n",
    "try:\n",
    "\n",
    "# Méthode 1: PC Algorithm (Peter-Clark)print(\"\\n--- Algorithme GES (Score-Based) ---\")\n",
    "\n",
    "print(\"\\n--- Algorithme PC (Constraint-Based) ---\")# Méthode 2: GES (Greedy Equivalence Search)\n",
    "\n",
    "try:\n",
    "\n",
    "    cg_pc = pc(data_array, alpha=0.05, indep_test='fisherz')    print(f\"Erreur avec PC: {e}\")\n",
    "\n",
    "    print(\"Graphe causal obtenu avec PC algorithm\")except Exception as e:\n",
    "\n",
    "        print(cg_pc.G.graph)\n",
    "\n",
    "    # Visualiser le graphe    print(\"\\nArêtes du graphe:\")\n",
    "\n",
    "    pyd = GraphUtils.to_pydot(cg_pc.G, labels=key_vars)    \n",
    "\n",
    "    pyd.write_png('causal_graph_pc.png')    plt.show()\n",
    "\n",
    "        plt.title('Graphe Causal - Algorithme PC')\n",
    "\n",
    "    img = mpimg.imread('causal_graph_pc.png')    plt.axis('off')\n",
    "\n",
    "    plt.figure(figsize=(12, 8))    plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
